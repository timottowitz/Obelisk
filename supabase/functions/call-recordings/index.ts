// Follow this setup guide to integrate the Deno language server with your editor:
// https://deno.land/manual/getting_started/setup_your_environment
// This enables autocomplete, go to definition, etc.

// Setup type definitions for built-in Supabase Runtime APIs
import "jsr:@supabase/functions-js/edge-runtime.d.ts";

import { Hono } from "jsr:@hono/hono";
import { cors } from "jsr:@hono/hono/cors";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { extractUserAndOrgId } from "../_shared/index.ts";
import { AzureBlobStorageService } from "../_shared/azure-storage.ts";

console.log("Hello from Functions!");

const app = new Hono();

// Helper to format duration
function formatDuration(milliseconds: number): string {
  if (!milliseconds) return "0s";
  const totalSeconds = Math.floor(milliseconds / 1000);
  const hours = Math.floor(totalSeconds / 3600);
  const minutes = Math.floor((totalSeconds % 3600) / 60);
  const seconds = totalSeconds % 60;
  if (hours > 0) {
    return `${hours}h ${minutes}m`;
  } else if (minutes > 0) {
    return `${minutes}min`;
  } else {
    return `${seconds}s`;
  }
}

// Helper to generate markdown report
function generateMarkdownReport(
  recording: any,
  transcript: string,
  analysis: any
): string {
  const formatDate = (isoString: string) => {
    const date = new Date(isoString);
    return date.toLocaleDateString("en-US", {
      year: "numeric",
      month: "long",
      day: "numeric",
      hour: "2-digit",
      minute: "2-digit",
    });
  };

  const formatDuration = (milliseconds: number) => {
    const totalSeconds = Math.floor(milliseconds / 1000);
    const hours = Math.floor(totalSeconds / 3600);
    const minutes = Math.floor((totalSeconds % 3600) / 60);
    const seconds = totalSeconds % 60;

    if (hours > 0) {
      return `${hours}h ${minutes}m ${seconds}s`;
    } else if (minutes > 0) {
      return `${minutes}m ${seconds}s`;
    } else {
      return `${seconds}s`;
    }
  };

  return `# Legal Meeting Analysis Report

## 📋 Meeting Information
- **Meeting ID**: ${recording.id}
- **Title**: ${recording.title}
- **Date & Time**: ${formatDate(recording.start_time)}
- **Duration**: ${formatDuration(recording.duration)}
- **Participants**: ${recording.participants?.join(", ") || "Not specified"}

## 🎯 Executive Summary
${analysis.summary || "No summary available"}

## 📊 Meeting Metrics
- **Sentiment**: ${
    analysis.sentiment
      ? analysis.sentiment.charAt(0).toUpperCase() + analysis.sentiment.slice(1)
      : "N/A"
  }
- **Word Count**: ${recording.word_count || 0}
- **Action Items**: ${analysis.actionItems?.length || 0}
- **Decisions Made**: ${analysis.decisions?.length || 0}
- **Risk Items**: ${analysis.risks?.length || 0}

## 🔑 Key Points
${
  analysis.keyPoints?.length > 0
    ? analysis.keyPoints
        .map((point: string, i: number) => `${i + 1}. ${point}`)
        .join("\n")
    : "No key points identified"
}

## ✅ Action Items
${
  analysis.actionItems?.length > 0
    ? analysis.actionItems
        .map((item: any) => {
          const assignee = item.assignee
            ? ` - Assigned to: ${item.assignee}`
            : "";
          const dueDate = item.dueDate ? ` - Due: ${item.dueDate}` : "";
          return `- [ ] ${item.task || item}${assignee}${dueDate}`;
        })
        .join("\n")
    : "No action items identified"
}

## 🎯 Decisions Made
${
  analysis.decisions?.length > 0
    ? analysis.decisions
        .map((decision: string, i: number) => `${i + 1}. ${decision}`)
        .join("\n")
    : "No decisions recorded"
}

## ⚠️ Risk Analysis
${
  analysis.risks?.length > 0
    ? analysis.risks
        .map((risk: any) => {
          return `### ${risk.risk || risk}
- **Severity**: ${risk.severity || "Medium"}
- **Mitigation**: ${risk.mitigation || "To be determined"}`;
        })
        .join("\n\n")
    : "No significant risks identified"
}

## 📋 Compliance Notes
${
  analysis.compliance?.length > 0
    ? analysis.compliance.map((note: string) => `- ${note}`).join("\n")
    : "No compliance notes"
}

## 📌 Follow-up Tasks
${
  analysis.followUp?.length > 0
    ? analysis.followUp.map((task: string) => `- [ ] ${task}`).join("\n")
    : "No follow-up tasks identified"
}

## 🏷️ Topics Discussed
${
  analysis.topics?.length > 0
    ? analysis.topics.map((topic: string) => `- ${topic}`).join("\n")
    : "Topics not identified"
}

## 📝 Full Transcript

${transcript || "Transcript not available"}

---

*Generated by Call Caps AI Legal Analysis System*  
*Powered by OpenAI Whisper & GPT-4*  
*Generated on: ${new Date().toLocaleDateString("en-US", {
    year: "numeric",
    month: "long",
    day: "numeric",
    hour: "2-digit",
    minute: "2-digit",
  })}*

**Confidentiality Notice**: This document contains attorney-client privileged information and is strictly confidential.
`;
}

// Configure CORS with proper options handling
app.use(
  "*",
  cors({
    origin: "*",
    allowMethods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allowHeaders: ["Content-Type", "Authorization", "X-Org-Id", "X-User-Id"],
    credentials: true,
  })
);

// Middleware for user and org extraction
app.use("/call-recordings", extractUserAndOrgId);
app.use("/call-recordings/:id/process", extractUserAndOrgId);

// Handle OPTIONS requests for all routes
app.options("*", (c) => {
  return c.text("", 200);
});

// Main route for /call-recordings
app.get("/call-recordings", async (c) => {
  const orgId = c.get("orgId");
  const userId = c.get("userId");

  try {
    const supabaseUrl = Deno.env.get("SUPABASE_URL") ?? "";
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";
    const supabase = createClient(supabaseUrl, supabaseServiceKey, {
      auth: { persistSession: false },
    });

    const org = await supabase
      .schema("private")
      .from("organizations")
      .select("*")
      .eq("clerk_organization_id", orgId)
      .single();
    if (org.error) {
      console.log(org);
      return c.json({ error: "Organization not found" }, 404);
    }
    const schema = org.data?.schema_name.toLowerCase();
    if (!schema) {
      return c.json({ error: "Organization not found" }, 404);
    }

    const user = await supabase
      .schema("private")
      .from("users")
      .select("*")
      .eq("clerk_user_id", userId)
      .single();
    if (user.error) {
      return c.json({ error: "User not found" }, 404);
    }
    const member = await supabase
      .schema("private")
      .from("organization_members")
      .select("*")
      .eq("user_id", user.data?.id)
      .eq("organization_id", org.data?.id)
      .single();
    if (member.error) {
      return c.json({ error: "Member not found" }, 404);
    }

    // Parse query params
    const url = new URL(c.req.url);
    const limit = parseInt(url.searchParams.get("limit") || "20");
    const offset = parseInt(url.searchParams.get("offset") || "0");
    const orderBy = url.searchParams.get("orderBy") || "start_time";
    const orderDirection = (url.searchParams.get("orderDirection") ||
      "desc") as "asc" | "desc";
    const search = url.searchParams.get("search") || undefined;
    const status = url.searchParams.get("status") || undefined;
    const startDate = url.searchParams.get("startDate") || undefined;
    const endDate = url.searchParams.get("endDate") || undefined;

    // Check if requesting a specific recording by ID
    const pathParts = url.pathname.split("/");
    const recordingId = pathParts[pathParts.length - 1];
    const table = `call_recordings`;

    if (recordingId && recordingId !== "call-recordings") {
      // Get single recording
      const { data: recording, error } = await supabase
        .schema(schema)
        .from(table)
        .select("*")
        .eq("member_id", member.data?.id)
        .eq("id", recordingId)
        .single();
      if (error || !recording) {
        return c.json({ error: "Recording not found" }, 404);
      }
      return c.json({ recording }, 200);
    }

    let query = supabase
      .schema(schema)
      .from(table)
      .select("*", { count: "exact" })
      .eq("member_id", member.data?.id);
    if (search) {
      query = query.or(`title.ilike.%${search}%,participants.cs.{${search}}`);
    }
    if (status) {
      query = query.eq("status", status);
    }
    if (startDate) {
      query = query.gte("start_time", startDate);
    }
    if (endDate) {
      query = query.lte("start_time", endDate);
    }
    query = query.order(orderBy, { ascending: orderDirection === "asc" });
    query = query.range(offset, offset + limit - 1);
    const { data: recordings, error, count } = await query;
    if (error) {
      return c.json(
        { error: "Failed to fetch recordings", details: error },
        500
      );
    }
    const formattedRecordings = (recordings || []).map((recording: any) => ({
      ...recording,
      date: new Date(recording.start_time).toLocaleDateString("en-US", {
        weekday: "long",
        month: "long",
        day: "numeric",
      }),
      time: new Date(recording.start_time).toLocaleTimeString("en-US", {
        hour: "numeric",
        minute: "2-digit",
      }),
      duration: formatDuration(recording.duration),
      transcript: recording.ai_analysis
        ? {
            summary: recording.ai_summary,
            actionItems: recording.action_items || [],
            keyTopics: recording.key_topics || [],
            sentiment: recording.sentiment,
            wordCount: recording.word_count,
          }
        : null,
    }));
    return c.json(
      {
        recordings: formattedRecordings,
        total: count || 0,
        limit,
        offset,
      },
      200
    );
  } catch (error: any) {
    return c.json({ error: error.message }, 500);
  }
});

// Upload recording route
app.post("/call-recordings", async (c) => {
  const orgId = c.get("orgId");
  const userId = c.get("userId");

  try {
    const supabaseUrl = Deno.env.get("SUPABASE_URL") ?? "";
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";
    const supabase = createClient(supabaseUrl, supabaseServiceKey, {
      auth: { persistSession: false },
    });

    const org = await supabase
      .schema("private")
      .from("organizations")
      .select("*")
      .eq("clerk_organization_id", orgId)
      .single();
    if (org.error) {
      console.log(org);
      return c.json({ error: "Organization not found" }, 404);
    }
    const schema = org.data?.schema_name.toLowerCase();
    if (!schema) {
      return c.json({ error: "Organization not found" }, 404);
    }

    const user = await supabase
      .schema("private")
      .from("users")
      .select("*")
      .eq("clerk_user_id", userId)
      .single();
    if (user.error) {
      return c.json({ error: "User not found" }, 404);
    }
    const member = await supabase
      .schema("private")
      .from("organization_members")
      .select("*")
      .eq("user_id", user.data?.id)
      .eq("organization_id", org.data?.id)
      .single();
    if (member.error) {
      return c.json({ error: "Member not found" }, 404);
    }

    // Parse request body
    const body = await c.req.json();
    const {
      recordingBlob,
      mimeType,
      duration,
      startTime,
      endTime,
      title,
      participants,
    } = body;

    if (!recordingBlob || !mimeType || !duration || !startTime || !title) {
      return c.json(
        {
          error:
            "Missing required fields: recordingBlob, mimeType, duration, startTime, title",
        },
        400
      );
    }

    const recordingsTable = `call_recordings`;
    const settingsTable = `user_settings`;
    const queueTable = `processing_queue`;

    // Get user's Azure credentials from settings, fallback to environment variables
    const { data: settings, error: settingsError } = await supabase
      .schema(schema)
      .from(settingsTable)
      .select("azure_connection_string")
      .eq("member_id", member.data?.id)
      .single();

    // Use user settings if available, otherwise use environment variables
    let azureConnectionString = settings?.azure_connection_string;
    if (!azureConnectionString) {
      azureConnectionString = Deno.env.get("AZURE_CONNECTION_STRING");
    }

    if (!azureConnectionString) {
      return c.json(
        {
          error:
            "Azure storage not configured. Please add your Azure connection string in settings or configure AZURE_CONNECTION_STRING environment variable.",
        },
        400
      );
    }

    // Parse Azure connection string
    const connectionString = azureConnectionString;
    const accountName = connectionString.match(/AccountName=([^;]+)/)?.[1];
    const accountKey = connectionString.match(/AccountKey=([^;]+)/)?.[1];

    if (!accountName || !accountKey) {
      return c.json({ error: "Invalid Azure connection string format" }, 400);
    }

    // Create recording record in database
    const { data: recording, error: insertError } = await supabase
      .schema(schema)
      .from(recordingsTable)
      .insert({
        member_id: member.data?.id,
        title,
        start_time: startTime,
        end_time: endTime,
        duration,
        participants: participants || [],
        mime_type: mimeType,
        status: "uploading",
        has_video: true,
        has_audio: true,
      })
      .select()
      .single();

    if (insertError || !recording) {
      console.log("insertError", insertError);
      return c.json(
        { error: "Failed to create recording record", details: insertError },
        500
      );
    }

    try {
      // Initialize Azure Blob Storage
      const azureStorage = new AzureBlobStorageService({
        accountName,
        accountKey,
        containerName: "callcaps-recordings",
      });

      // Convert base64 to ArrayBuffer
      const binaryString = atob(recordingBlob);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // Upload to Azure Blob Storage
      const uploadResult = await azureStorage.uploadVideo(
        user.data?.id,
        recording.id,
        bytes,
        mimeType
      );

      // Update recording with Azure URLs
      const { error: updateError } = await supabase
        .schema(schema)
        .from(recordingsTable)
        .update({
          azure_video_url: uploadResult.blobUrl,
          azure_video_blob_name: uploadResult.blobName,
          file_size: bytes.length,
          status: "uploaded",
        })
        .eq("id", recording.id);

      if (updateError) {
        console.error(
          "Failed to update recording with Azure URLs:",
          updateError
        );
      }

      // Add to processing queue for transcription
      const { error: queueError } = await supabase
        .schema(schema)
        .from(queueTable)
        .insert({
          recording_id: recording.id,
          task_type: "transcribe",
          status: "pending",
        });

      if (queueError) {
        console.error("Failed to add to processing queue:", queueError);
      }

      return c.json(
        {
          success: true,
          recording: {
            id: recording.id,
            title: recording.title,
            status: "uploaded",
            azure_video_url: uploadResult.blobUrl,
            duration: recording.duration,
            start_time: recording.start_time,
            end_time: recording.end_time,
          },
        },
        200
      );
    } catch (uploadError: any) {
      console.log("uploadError", uploadError);
      // Update recording status to failed
      await supabase
        .schema(schema)
        .from(recordingsTable)
        .update({
          status: "failed",
          processing_error: uploadError.message,
        })
        .eq("id", recording.id);

      return c.json(
        { error: "Failed to upload to Azure", details: uploadError.message },
        500
      );
    }
  } catch (error: any) {
    return c.json({ error: error.message }, 500);
  }
});

// Process recording route
app.post("/call-recordings/:id/process", async (c) => {
  const orgId = c.get("orgId");
  const userId = c.get("userId");
  console.log("orgId", orgId);
  console.log("userId", userId);

  try {
    const supabaseUrl = Deno.env.get("SUPABASE_URL") ?? "";
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";
    const supabase = createClient(supabaseUrl, supabaseServiceKey, {
      auth: { persistSession: false },
    });

    const org = await supabase
      .schema("private")
      .from("organizations")
      .select("*")
      .eq("clerk_organization_id", orgId)
      .single();
    if (org.error) {
      return c.json({ error: "Organization not found" }, 404);
    }
    const schema = org.data?.schema_name.toLowerCase();
    if (!schema) {
      return c.json({ error: "Organization not found" }, 404);
    }

    const user = await supabase
      .schema("private")
      .from("users")
      .select("*")
      .eq("clerk_user_id", userId)
      .single();
    if (user.error) {
      return c.json({ error: "User not found" }, 404);
    }
    const member = await supabase
      .schema("private")
      .from("organization_members")
      .select("*")
      .eq("user_id", user.data?.id)
      .eq("organization_id", org.data?.id)
      .single();
    if (member.error) {
      return c.json({ error: "Member not found" }, 404);
    }

    // Get recording ID from URL
    const url = new URL(c.req.url);
    const pathParts = url.pathname.split("/");
    const recordingId = pathParts[pathParts.length - 2]; // /call-recordings/:id/process
    if (!recordingId || recordingId === "call-recordings") {
      return c.json({ error: "Recording ID required" }, 400);
    }

    // Parse request body
    const body = await c.req.json();
    const { taskType = "all" } = body;

    const recordingsTable = `call_recordings`;
    const settingsTable = `user_settings`;
    const queueTable = `processing_queue`;

    // Get recording details
    const { data: recording, error: recordingError } = await supabase
      .schema(schema)
      .from(recordingsTable)
      .select("*")
      .eq("id", recordingId)
      .eq("member_id", member.data?.id)
      .single();

    if (recordingError || !recording) {
      return c.json({ error: "Recording not found" }, 404);
    }

    // Get user settings for API keys, fallback to environment variables
    const { data: settings, error: settingsError } = await supabase
      .schema(schema)
      .from(settingsTable)
      .select(
        "openai_api_key, azure_connection_string, ai_model, temperature, custom_prompts"
      )
      .eq("member_id", member.data?.id)
      .single();

    // Use user settings if available, otherwise use environment variables
    let openaiApiKey = settings?.openai_api_key;
    let azureConnectionString = settings?.azure_connection_string;

    if (!openaiApiKey) {
      openaiApiKey = Deno.env.get("OPENAI_API_KEY");
    }

    if (!azureConnectionString) {
      azureConnectionString = Deno.env.get("AZURE_CONNECTION_STRING");
    }

    if (!openaiApiKey) {
      return c.json(
        {
          error:
            "OpenAI API key not configured. Please add your API key in settings or configure OPENAI_API_KEY environment variable.",
        },
        400
      );
    }

    // Update recording status
    await supabase
      .schema(schema)
      .from(recordingsTable)
      .update({ status: "processing" })
      .eq("id", recordingId);

    try {
      let transcriptText = recording.transcript_text;
      let transcriptSegments = recording.transcript_segments;

      // Step 1: Transcribe if needed
      if (
        (taskType === "transcribe" || taskType === "all") &&
        !transcriptText
      ) {
        console.log("Starting transcription...");

        // Parse Azure connection string
        const connectionString = azureConnectionString;
        const accountName = connectionString.match(/AccountName=([^;]+)/)?.[1];
        const accountKey = connectionString.match(/AccountKey=([^;]+)/)?.[1];

        if (!accountName || !accountKey) {
          throw new Error("Invalid Azure connection string");
        }

        // Initialize Azure Blob Storage
        const azureStorage = new AzureBlobStorageService({
          accountName,
          accountKey,
          containerName: "callcaps-recordings",
        });

        // Download video from Azure
        const videoData = await azureStorage.downloadBlob(
          recording.azure_video_blob_name
        );

        // Create form data for OpenAI Whisper
        const formData = new FormData();
        formData.append(
          "file",
          new Blob([videoData], { type: recording.mime_type }),
          "recording.webm"
        );
        formData.append("model", "whisper-1");
        formData.append("language", "en");
        formData.append("response_format", "verbose_json");
        formData.append("temperature", "0.2");

        // Call OpenAI Whisper API
        const whisperResponse = await fetch(
          "https://api.openai.com/v1/audio/transcriptions",
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${openaiApiKey}`,
            },
            body: formData,
          }
        );

        if (!whisperResponse.ok) {
          const error = await whisperResponse.text();
          throw new Error(`Whisper API error: ${error}`);
        }

        const whisperResult = await whisperResponse.json();
        transcriptText = whisperResult.text;
        transcriptSegments = whisperResult.segments || [];

        // Update recording with transcript
        await supabase
          .schema(schema)
          .from(recordingsTable)
          .update({
            transcript_text: transcriptText,
            transcript_segments: transcriptSegments,
            word_count: transcriptText.split(/\s+/).length,
          })
          .eq("id", recordingId);
      }

      // Step 2: Analyze transcript if needed
      let analysis = recording.ai_analysis;
      if (
        (taskType === "analyze" || taskType === "all") &&
        transcriptText &&
        !analysis
      ) {
        console.log("Starting AI analysis...");

        const systemPrompt =
          settings?.custom_prompts?.analysis ||
          `You are an AI assistant that analyzes meeting recordings and call transcripts for legal professionals. 
        Provide a structured analysis including:
        1. Executive summary
        2. Key points and decisions
        3. Action items with clear ownership
        4. Risk analysis and compliance notes
        5. Follow-up tasks
        
        Format your response as JSON with the following structure:
        {
          "summary": "Brief executive summary",
          "keyPoints": ["point 1", "point 2"],
          "actionItems": [{"task": "task description", "assignee": "person", "dueDate": "date"}],
          "decisions": ["decision 1", "decision 2"],
          "risks": [{"risk": "description", "severity": "high/medium/low", "mitigation": "steps"}],
          "compliance": ["note 1", "note 2"],
          "followUp": ["task 1", "task 2"],
          "sentiment": "positive|neutral|negative",
          "topics": ["topic 1", "topic 2"]
        }`;

        // Call OpenAI GPT for analysis
        const gptResponse = await fetch(
          "https://api.openai.com/v1/chat/completions",
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${openaiApiKey}`,
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              model: settings?.ai_model || "gpt-4o-mini",
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: `Please analyze this legal meeting transcript:\n\n${transcriptText}`,
                },
              ],
              temperature: settings?.temperature || 0.3,
              max_tokens: 2000,
            }),
          }
        );

        if (!gptResponse.ok) {
          const error = await gptResponse.text();
          throw new Error(`GPT API error: ${error}`);
        }

        const gptResult = await gptResponse.json();
        const analysisText = gptResult.choices[0].message.content;

        try {
          analysis = JSON.parse(analysisText);
        } catch (parseError) {
          // Fallback if JSON parsing fails
          analysis = {
            summary: analysisText,
            keyPoints: [],
            actionItems: [],
            decisions: [],
            risks: [],
            compliance: [],
            followUp: [],
            sentiment: "neutral",
            topics: [],
          };
        }

        // Update recording with analysis
        await supabase
          .schema(schema)
          .from(recordingsTable)
          .update({
            ai_analysis: analysis,
            ai_summary: analysis.summary,
            action_items: analysis.actionItems || [],
            key_topics: analysis.topics || [],
            sentiment: analysis.sentiment || "neutral",
            risk_analysis: analysis.risks || [],
          })
          .eq("id", recordingId);
      }

      // Step 3: Generate and upload markdown report
      if (transcriptText && analysis) {
        console.log("Generating markdown report...");

        const markdown = generateMarkdownReport(
          recording,
          transcriptText,
          analysis
        );

        // Parse Azure connection string
        const connectionString = azureConnectionString;
        const accountName = connectionString.match(/AccountName=([^;]+)/)?.[1];
        const accountKey = connectionString.match(/AccountKey=([^;]+)/)?.[1];

        if (accountName && accountKey) {
          // Initialize Azure Blob Storage
          const azureStorage = new AzureBlobStorageService({
            accountName,
            accountKey,
            containerName: "callcaps-recordings",
          });

          // Upload markdown to Azure
          const transcriptResult = await azureStorage.uploadTranscript(
            user.data?.id,
            recordingId,
            markdown
          );

          // Update recording with transcript URL
          await supabase
            .schema(schema)
            .from(recordingsTable)
            .update({
              azure_transcript_url: transcriptResult.blobUrl,
              azure_transcript_blob_name: transcriptResult.blobName,
              status: "processed",
              processed_at: new Date().toISOString(),
            })
            .eq("id", recordingId);
        }
      }

      // Update processing queue
      await supabase
        .schema(schema)
        .from(queueTable)
        .update({
          status: "completed",
          completed_at: new Date().toISOString(),
        })
        .eq("recording_id", recordingId)
        .eq("task_type", taskType === "all" ? "transcribe" : taskType);

      return c.json(
        {
          success: true,
          recording: {
            id: recording.id,
            title: recording.title,
            status: "processed",
            transcript_text: transcriptText,
            ai_analysis: analysis,
            ai_summary: analysis?.summary,
          },
        },
        200
      );
    } catch (processingError: any) {
      console.error("Processing error:", processingError);

      // Update recording status to failed
      await supabase
        .schema(schema)
        .from(recordingsTable)
        .update({
          status: "failed",
          processing_error: processingError.message,
        })
        .eq("id", recordingId);

      // Update processing queue
      await supabase
        .schema(schema)
        .from(queueTable)
        .update({
          status: "failed",
          error_message: processingError.message,
          retry_count: (recording.retry_count || 0) + 1,
        })
        .eq("recording_id", recordingId);

      return c.json(
        { error: "Processing failed", details: processingError.message },
        500
      );
    }
  } catch (error: any) {
    return c.json({ error: error.message }, 500);
  }
});

export default app;

/* To invoke locally:

  1. Run `supabase start` (see: https://supabase.com/docs/reference/cli/supabase-start)
  2. Make an HTTP request:

  curl -i --location --request POST 'http://127.0.0.1:54321/functions/v1/call-recordings' \
    --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0' \
    --header 'Content-Type: application/json' \
    --data '{"name":"Functions"}'

*/
